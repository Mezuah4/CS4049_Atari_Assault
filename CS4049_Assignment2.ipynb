{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "CS4049_Assignment2.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DMsZuhhASEG"
   },
   "source": [
    "# CS4049 Assignment 2 - Atari Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Unb-wSWz9znM",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9b73e348-e28e-49e5-d1db-cc78f79a230d"
   },
   "source": [
    "# !pip install tensorflow==2.3.1 gym keras-rl2 gym[atari]\n",
    "# !apt-get install -y xvfb python-opengl ffmeg > /def/null 2>&1\n",
    "\n",
    "# !pip install atari_py==0.2.6 gym==0.17.2 keras-rl2 pyglet\n",
    "# !pip install -U colabgymrender"
   ],
   "execution_count": 74,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VGmEhOQVAWUp"
   },
   "source": [
    "# For deep neural networks\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tf_slim as slim\n",
    "\n",
    "# For data representation\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# For handling files\n",
    "import os\n",
    "\n",
    "# For plotting graphs\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# OpenAI Gym\n",
    "import gym\n",
    "env = gym.make(\"Assault-v0\")\n",
    "# I have installed pyglet-1.5.11 for it work with BigSur"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 126] The specified module could not be found",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_13344/2465427500.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;31m# OpenAI Gym\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mgym\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m \u001B[0menv\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgym\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmake\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Assault-v0\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m \u001B[1;31m# I have installed pyglet-1.5.11 for it work with BigSur\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37_0\\lib\\site-packages\\gym\\envs\\registration.py\u001B[0m in \u001B[0;36mmake\u001B[1;34m(id, **kwargs)\u001B[0m\n\u001B[0;32m    143\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    144\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mmake\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mid\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 145\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mregistry\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmake\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mid\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    146\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    147\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mspec\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mid\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37_0\\lib\\site-packages\\gym\\envs\\registration.py\u001B[0m in \u001B[0;36mmake\u001B[1;34m(self, path, **kwargs)\u001B[0m\n\u001B[0;32m     88\u001B[0m             \u001B[0mlogger\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Making new env: %s'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     89\u001B[0m         \u001B[0mspec\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mspec\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 90\u001B[1;33m         \u001B[0menv\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mspec\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmake\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     91\u001B[0m         \u001B[1;31m# We used to have people override _reset/_step rather than\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     92\u001B[0m         \u001B[1;31m# reset/step. Set _gym_disable_underscore_compat = True on\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37_0\\lib\\site-packages\\gym\\envs\\registration.py\u001B[0m in \u001B[0;36mmake\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m     57\u001B[0m             \u001B[0menv\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mentry_point\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0m_kwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 59\u001B[1;33m             \u001B[0mcls\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mentry_point\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     60\u001B[0m             \u001B[0menv\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcls\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0m_kwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     61\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37_0\\lib\\site-packages\\gym\\envs\\registration.py\u001B[0m in \u001B[0;36mload\u001B[1;34m(name)\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m     \u001B[0mmod_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mattr_name\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\":\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m     \u001B[0mmod\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mimportlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimport_module\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmod_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m     \u001B[0mfn\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmod\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mattr_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37_0\\lib\\importlib\\__init__.py\u001B[0m in \u001B[0;36mimport_module\u001B[1;34m(name, package)\u001B[0m\n\u001B[0;32m    125\u001B[0m                 \u001B[1;32mbreak\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    126\u001B[0m             \u001B[0mlevel\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 127\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_bootstrap\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_gcd_import\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mlevel\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpackage\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    128\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    129\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37_0\\lib\\importlib\\_bootstrap.py\u001B[0m in \u001B[0;36m_gcd_import\u001B[1;34m(name, package, level)\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37_0\\lib\\importlib\\_bootstrap.py\u001B[0m in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37_0\\lib\\importlib\\_bootstrap.py\u001B[0m in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37_0\\lib\\importlib\\_bootstrap.py\u001B[0m in \u001B[0;36m_load_unlocked\u001B[1;34m(spec)\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37_0\\lib\\importlib\\_bootstrap_external.py\u001B[0m in \u001B[0;36mexec_module\u001B[1;34m(self, module)\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37_0\\lib\\importlib\\_bootstrap.py\u001B[0m in \u001B[0;36m_call_with_frames_removed\u001B[1;34m(f, *args, **kwds)\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37_0\\lib\\site-packages\\gym\\envs\\atari\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mgym\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0menvs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0matari\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0matari_env\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mAtariEnv\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37_0\\lib\\site-packages\\gym\\envs\\atari\\atari_env.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m     \u001B[1;32mimport\u001B[0m \u001B[0matari_py\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m \u001B[1;32mexcept\u001B[0m \u001B[0mImportError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m     raise error.DependencyNotInstalled(\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37_0\\lib\\site-packages\\atari_py\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0male_python_interface\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0m_game_dir\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mabspath\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdirname\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m__file__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"atari_roms\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37_0\\lib\\site-packages\\atari_py\\ale_python_interface.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m     ale_lib = cdll.LoadLibrary(os.path.join(os.path.dirname(__file__),\n\u001B[1;32m---> 18\u001B[1;33m                                             'ale_interface/ale_c.dll'))\n\u001B[0m\u001B[0;32m     19\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[0male_lib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mALE_new\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0margtypes\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37_0\\lib\\ctypes\\__init__.py\u001B[0m in \u001B[0;36mLoadLibrary\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m    432\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    433\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mLoadLibrary\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 434\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dlltype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    435\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    436\u001B[0m \u001B[0mcdll\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mLibraryLoader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mCDLL\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37_0\\lib\\ctypes\\__init__.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, name, mode, handle, use_errno, use_last_error)\u001B[0m\n\u001B[0;32m    354\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    355\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mhandle\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 356\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_handle\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_dlopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    357\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    358\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_handle\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhandle\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mOSError\u001B[0m: [WinError 126] The specified module could not be found"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "ajAIsHnC9znM",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2eb36557-a1ec-4e14-c602-74d20c6b78b4"
   },
   "source": [
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ],
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "xV1YY6WZ9znO"
   },
   "source": [
    "# Reinforcement Learning with Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 1.1: Create Environment (Investigate Action Space)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SluE0QkWHVxJ"
   },
   "source": [
    "# Describe Action & Observation Space\n",
    "print(\"Action space: \", env.action_space)\n",
    "print(\"Observation space: \", env.observation_space)\n",
    "\n",
    "env.reset()\n",
    "next_obs, reward, done, info = env.step(0)\n",
    "print(info)"
   ],
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space:  Discrete(7)\n",
      "Observation space:  Box(250, 160, 3)\n",
      "{'ale.lives': 4}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward per episode: 216.3\n"
     ]
    }
   ],
   "source": [
    "# class RandomAgent():\n",
    "#     def __init__(self, env):\n",
    "#         self.action_size = env.action_space.n\n",
    "#\n",
    "#     def get_action(self, observation):\n",
    "#         return random.choice(range(self.action_size))\n",
    "#\n",
    "# reward_episodes = []\n",
    "# numberOfEpisodes = 10\n",
    "# agent = RandomAgent(env)\n",
    "# for ep in range(numberOfEpisodes):\n",
    "#     current_obs = env.reset()\n",
    "#     done = False\n",
    "#     total_reward_ep = 0\n",
    "#     while not done:\n",
    "#         action = agent.get_action(current_obs)\n",
    "#         next_obs, reward, done, info = env.step(action)\n",
    "#         env.render()\n",
    "#         total_reward_ep += reward\n",
    "#     reward_episodes.append(total_reward_ep)\n",
    "#\n",
    "# print(\"Average reward per episode: {}\".format(np.sum(reward_episodes)/numberOfEpisodes))\n",
    "# env.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 1.3: Pre-Processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x22b736d5ec8>"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "\n",
    "def preprocess_observations(observation):\n",
    "\n",
    "    # Slice Top Off\n",
    "    img = observation[34:250:2, ::2]\n",
    "\n",
    "    # Grey Scale\n",
    "    img = img.mean(axis=2)\n",
    "    img = (img - 128).astype(np.int8)\n",
    "\n",
    "    return img.reshape(108, 80, 1)\n",
    "\n",
    "plt.imshow(obs)\n",
    "plt.show()\n",
    "plt.imshow(preprocess_observations(obs).reshape(108, 80), cmap=\"gray\", vmin=-128, vmax=127)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 1.4: Implement Deep Convolutional Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Deep Convolutional Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "def q_network(X_state, name):\n",
    "    prev_layer = X_state / 128 #the values will be between [-1, 1]\n",
    "    initializer = tf.variance_scaling_initializer()\n",
    "    hidden_activation = tf.nn.relu\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        prev_layer = tf.layers.conv2d(prev_layer, filters=32,\n",
    "                                      kernel_size = 8, strides = 4,\n",
    "                                      padding=\"SAME\", activation= hidden_activation,\n",
    "                                      kernel_initializer = initializer)\n",
    "        prev_layer = tf.layers.conv2d(prev_layer, filters=64,\n",
    "                                      kernel_size = 4, strides = 2,\n",
    "                                      padding=\"SAME\", activation= hidden_activation,\n",
    "                                      kernel_initializer = initializer)\n",
    "        prev_layer = tf.layers.conv2d(prev_layer, filters=64,\n",
    "                                      kernel_size = 3, strides = 1,\n",
    "                                      padding=\"SAME\", activation= hidden_activation,\n",
    "                                      kernel_initializer = initializer)\n",
    "        last_conv_layer_flat = tf.reshape(prev_layer, shape= [-1, 64 * 12*10])\n",
    "        hidden = tf.layers.dense(last_conv_layer_flat, 512,\n",
    "                                 activation = hidden_activation, kernel_initializer = initializer)\n",
    "        outputs = tf.layers.dense(hidden, env.action_space.n, kernel_initializer = initializer)\n",
    "    trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope = scope.name)\n",
    "    trainable_vars_by_name = { var.name[len(scope.name):] : var for var in trainable_vars}\n",
    "    return outputs, trainable_vars_by_name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Using Deep Convolutional Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "class QLearningAgent():\n",
    "    def __init__(self, env, learning_rate = 0.001, momemtum = 0.95):\n",
    "        self.action_size = env.action_space.n\n",
    "        self.loss_val = np.infty\n",
    "        tf.reset_default_graph()\n",
    "        tf.disable_eager_execution()\n",
    "\n",
    "        self.discount_rate = 0.99\n",
    "\n",
    "        self.checkpoint_path = \"./my_dqn_boxing.ckpt\"\n",
    "\n",
    "        self.X_state = tf.placeholder(tf.float32, shape= [None, 96, 80, 1])\n",
    "        self.online_q_values, self.online_vars = q_network(self.X_state, name = \"q_networks/online\")\n",
    "        self.target_q_values, self.target_vars = q_network(self.X_state, name = \"q_networks/target\")\n",
    "\n",
    "        #Define the operations to copy the online network to the target network\n",
    "        self.copy_ops = [ target_var.assign(self.online_vars[var_name])\n",
    "                          for var_name, target_var in self.target_vars.items()]\n",
    "        self.copy_online_to_target = tf.group(*self.copy_ops)\n",
    "\n",
    "        # The structure of the training\n",
    "        with tf.variable_scope(\"train\"):\n",
    "            self.X_action = tf.placeholder(tf.int32, shape=[None])\n",
    "            self.y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "            self.q_value = tf.reduce_sum(self.online_q_values * tf.one_hot(self.X_action, self.action_size),\n",
    "                                         axis=1, keepdims = True)\n",
    "\n",
    "            self.error = tf.abs( self.y - self.q_value) #A value between 0 and infty\n",
    "            self.clipped_error = tf.clip_by_value(self.error, 0.0, 1.0) #If it is above 1 then it becomes 1\n",
    "            self.linear_error = 2 * (self.error - self.clipped_error)\n",
    "            self.loss = tf.reduce_mean(tf.square(self.clipped_error) + self.linear_error)\n",
    "\n",
    "            self.global_step = tf.Variable(0, trainable = False, name = \"global_step\")\n",
    "            self.optimizer = tf.train.MomentumOptimizer(learning_rate, momentum = momemtum, use_nesterov = True)\n",
    "            self.training_op = self.optimizer.minimize(self.loss, global_step = self.global_step)\n",
    "\n",
    "        # Saving\n",
    "        self.saver = tf.train.Saver()\n",
    "        self.sess = tf.Session()\n",
    "        if os.path.isfile(self.checkpoint_path + \".index\"):\n",
    "            self.saver.restore(self.sess, self.checkpoint_path)\n",
    "        else:\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "            self.sess.run(self.copy_online_to_target)\n",
    "\n",
    "    def get_action(self, q_values, step):\n",
    "        epsilon = max(0.1, 1 - (0.9/2000000) * step)\n",
    "        if np.random.rand() < epsilon:\n",
    "            return np.random.randint(self.action_size)\n",
    "        else:\n",
    "            return np.argmax(q_values)\n",
    "\n",
    "\n",
    "\n",
    "    def train(self, state_val, action_val, reward, next_state_val, continues):\n",
    "        next_q_values = self.target_q_values.eval(feed_dict={self.X_state : np.array([next_state_val])})\n",
    "        max_next_q_values = np.max(next_q_values , axis = 1, keepdims= True)\n",
    "        #We can now compute the target value\n",
    "        y_val = reward + continues * self.discount_rate *max_next_q_values\n",
    "        _ , self.loss_val = self.sess.run([self.training_op, self.loss],\n",
    "                                          feed_dict= {self.X_state: np.array([state_val]),\n",
    "                                                      self.X_action: np.array([action_val]),\n",
    "                                                      self.y : y_val})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train Model for 1,000,000 Training Steps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mezuah4\\AppData\\Local\\Temp/ipykernel_3040/1133026787.py:9: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From c:\\users\\mezuah4\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\layers\\convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From c:\\users\\mezuah4\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\Mezuah4\\AppData\\Local\\Temp/ipykernel_3040/1133026787.py:20: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "\t Training step 0/1000000 (0.0)% \t Loss  inf"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_observation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_3040/236797399.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     17\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mdone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m             \u001B[0mobs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0menv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 19\u001B[1;33m             \u001B[0mstate\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpreprocess_observation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     20\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m         q_values = agent.online_q_values.eval(feed_dict={\n",
      "\u001B[1;31mNameError\u001B[0m: name 'preprocess_observation' is not defined"
     ]
    }
   ],
   "source": [
    "agent = QLearningAgent(env)\n",
    "\n",
    "\n",
    "n_steps = 1000000\n",
    "copy_steps = 5000\n",
    "save_steps = 1000\n",
    "\n",
    "with agent.sess:\n",
    "    while True:\n",
    "        step = agent.global_step.eval()\n",
    "        if step >= n_steps:\n",
    "            break\n",
    "\n",
    "\n",
    "        print(\"\\r\\t Training step {}/{} ({:.1f})% \\t Loss{:5f}\".format(step,n_steps,step*100/ n_steps,agent.loss_val), end=\"\")\n",
    "\n",
    "        if done:\n",
    "            obs = env.reset()\n",
    "            state = preprocess_observation(obs)\n",
    "\n",
    "        q_values = agent.online_q_values.eval(feed_dict={\n",
    "            agent.X_state : [state]})\n",
    "        action = agent.get_action(q_values,step)\n",
    "\n",
    "        #We play the action from the agent\n",
    "        next_obs, reward, done, info = env.step(action)\n",
    "        next_state = preprocess_observation(next_obs)\n",
    "        agent.train(state, action, reward, next_state, 1.0 - done)\n",
    "\n",
    "        env.render()\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        if step % copy_steps ==0:\n",
    "            agent.copy_online_to_target.run()\n",
    "\n",
    "        if step % save_steps ==0:\n",
    "            agent.saver.save(agent.sess, agent.checkpoint_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyxQuhsvMG0p"
   },
   "source": [
    "# Reinforcement Learning with RAM"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9sFk9WrTMb7z"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJmMkfh8McdN"
   },
   "source": [
    "# Reinforcement Learning by Mixing Screen and RAM"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "a7X1Em8i9znR"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}