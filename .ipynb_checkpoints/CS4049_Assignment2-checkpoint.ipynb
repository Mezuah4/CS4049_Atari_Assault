{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DMsZuhhASEG"
   },
   "source": [
    "# CS4049 Assignment 2 - Atari Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Unb-wSWz9znM",
    "outputId": "9b73e348-e28e-49e5-d1db-cc78f79a230d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.3.1 gym keras-rl2 gym[atari]\n",
    "# !apt-get install -y xvfb python-opengl ffmeg > /def/null 2>&1\n",
    "\n",
    "# !pip install atari_py==0.2.6 gym==0.17.2 keras-rl2 pyglet\n",
    "# !pip install -U colabgymrender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VGmEhOQVAWUp"
   },
   "outputs": [],
   "source": [
    "# For deep neural networks\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tf_slim as slim\n",
    "\n",
    "# For data representation\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# For handling files\n",
    "import os\n",
    "\n",
    "# For plotting graphs\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# OpenAI Gym\n",
    "import gym\n",
    "env = gym.make(\"Assault-v0\")\n",
    "# I have installed pyglet-1.5.11 for it work with BigSur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ajAIsHnC9znM",
    "outputId": "2eb36557-a1ec-4e14-c602-74d20c6b78b4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping: no known devices.\n"
     ]
    }
   ],
   "source": [
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xV1YY6WZ9znO"
   },
   "source": [
    "# Reinforcement Learning with Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.1: Create Environment (Investigate Action Space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SluE0QkWHVxJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space:  Discrete(7)\n",
      "Observation space:  Box(250, 160, 3)\n",
      "{'ale.lives': 4}\n"
     ]
    }
   ],
   "source": [
    "# Describe Action & Observation Space\n",
    "print(\"Action space: \", env.action_space)\n",
    "print(\"Observation space: \", env.observation_space)\n",
    "\n",
    "env.reset()\n",
    "next_obs, reward, done, info = env.step(0)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# class RandomAgent():\n",
    "#     def __init__(self, env):\n",
    "#         self.action_size = env.action_space.n\n",
    "#\n",
    "#     def get_action(self, observation):\n",
    "#         return random.choice(range(self.action_size))\n",
    "#\n",
    "# reward_episodes = []\n",
    "# numberOfEpisodes = 10\n",
    "# agent = RandomAgent(env)\n",
    "# for ep in range(numberOfEpisodes):\n",
    "#     current_obs = env.reset()\n",
    "#     done = False\n",
    "#     total_reward_ep = 0\n",
    "#     while not done:\n",
    "#         action = agent.get_action(current_obs)\n",
    "#         next_obs, reward, done, info = env.step(action)\n",
    "#         env.render()\n",
    "#         total_reward_ep += reward\n",
    "#     reward_episodes.append(total_reward_ep)\n",
    "#\n",
    "# print(\"Average reward per episode: {}\".format(np.sum(reward_episodes)/numberOfEpisodes))\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.3: Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13adfab0970>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "\n",
    "def preprocess_observation(observation):\n",
    "\n",
    "    # Slice Top Off\n",
    "    img = observation[34:250:2, ::2]\n",
    "\n",
    "    # Grey Scale\n",
    "    img = img.mean(axis=2)\n",
    "    img = (img - 128).astype(np.int8)\n",
    "\n",
    "    return img.reshape(108, 80, 1)\n",
    "\n",
    "plt.imshow(obs)\n",
    "plt.show()\n",
    "plt.imshow(preprocess_observation(obs).reshape(108, 80), cmap=\"gray\", vmin=-128, vmax=127)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.4: Implement Deep Convolutional Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Deep Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def q_network(X_state, name):\n",
    "    prev_layer = X_state / 128 #the values will be between [-1, 1]\n",
    "    initializer = tf.variance_scaling_initializer()\n",
    "    hidden_activation = tf.nn.relu\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        prev_layer = tf.layers.conv2d(prev_layer, filters=32,\n",
    "                                      kernel_size = 8, strides = 4,\n",
    "                                      padding=\"SAME\", activation= hidden_activation,\n",
    "                                      kernel_initializer = initializer)\n",
    "        prev_layer = tf.layers.conv2d(prev_layer, filters=64,\n",
    "                                      kernel_size = 4, strides = 2,\n",
    "                                      padding=\"SAME\", activation= hidden_activation,\n",
    "                                      kernel_initializer = initializer)\n",
    "        prev_layer = tf.layers.conv2d(prev_layer, filters=64,\n",
    "                                      kernel_size = 3, strides = 1,\n",
    "                                      padding=\"SAME\", activation= hidden_activation,\n",
    "                                      kernel_initializer = initializer)\n",
    "        last_conv_layer_flat = tf.reshape(prev_layer, shape= [-1, 8960])\n",
    "        hidden = tf.layers.dense(last_conv_layer_flat, 512,\n",
    "                                 activation = hidden_activation, kernel_initializer = initializer)\n",
    "        outputs = tf.layers.dense(hidden, env.action_space.n, kernel_initializer = initializer)\n",
    "    trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope = scope.name)\n",
    "    trainable_vars_by_name = { var.name[len(scope.name):] : var for var in trainable_vars}\n",
    "    return outputs, trainable_vars_by_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Using Deep Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class QLearningAgent():\n",
    "    def __init__(self, env, learning_rate = 0.001, momemtum = 0.95):\n",
    "        self.action_size = env.action_space.n\n",
    "        self.loss_val = np.infty\n",
    "        tf.reset_default_graph()\n",
    "        tf.disable_eager_execution()\n",
    "\n",
    "        self.discount_rate = 0.99\n",
    "\n",
    "        self.checkpoint_path = \"./my_dqn_assault.ckpt\"\n",
    "\n",
    "        self.X_state = tf.placeholder(tf.float32, shape= [None, 108, 80, 1])\n",
    "        self.online_q_values, self.online_vars = q_network(self.X_state, name = \"q_networks/online\")\n",
    "        self.target_q_values, self.target_vars = q_network(self.X_state, name = \"q_networks/target\")\n",
    "\n",
    "        #Define the operations to copy the online network to the target network\n",
    "        self.copy_ops = [ target_var.assign(self.online_vars[var_name])\n",
    "                          for var_name, target_var in self.target_vars.items()]\n",
    "        self.copy_online_to_target = tf.group(*self.copy_ops)\n",
    "\n",
    "        # The structure of the training\n",
    "        with tf.variable_scope(\"train\"):\n",
    "            self.X_action = tf.placeholder(tf.int32, shape=[None])\n",
    "            self.y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "            self.q_value = tf.reduce_sum(self.online_q_values * tf.one_hot(self.X_action, self.action_size),\n",
    "                                         axis=1, keepdims = True)\n",
    "\n",
    "            self.error = tf.abs( self.y - self.q_value) #A value between 0 and infty\n",
    "            self.clipped_error = tf.clip_by_value(self.error, 0.0, 1.0) #If it is above 1 then it becomes 1\n",
    "            self.linear_error = 2 * (self.error - self.clipped_error)\n",
    "            self.loss = tf.reduce_mean(tf.square(self.clipped_error) + self.linear_error)\n",
    "\n",
    "            self.global_step = tf.Variable(0, trainable = False, name = \"global_step\")\n",
    "            self.optimizer = tf.train.MomentumOptimizer(learning_rate, momentum = momemtum, use_nesterov = True)\n",
    "            self.training_op = self.optimizer.minimize(self.loss, global_step = self.global_step)\n",
    "\n",
    "        # Saving\n",
    "        self.saver = tf.train.Saver()\n",
    "        self.sess = tf.Session()\n",
    "        if os.path.isfile(self.checkpoint_path + \".index\"):\n",
    "            self.saver.restore(self.sess, self.checkpoint_path)\n",
    "        else:\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "            self.sess.run(self.copy_online_to_target)\n",
    "\n",
    "    def get_action(self, q_values, step):\n",
    "        epsilon = max(0.1, 1 - (0.9/2000000) * step)\n",
    "        if np.random.rand() < epsilon:\n",
    "            return np.random.randint(self.action_size)\n",
    "        else:\n",
    "            return np.argmax(q_values)\n",
    "\n",
    "\n",
    "\n",
    "    def train(self, state_val, action_val, reward, next_state_val, continues):\n",
    "        next_q_values = self.target_q_values.eval(feed_dict={self.X_state : np.array([next_state_val])})\n",
    "        max_next_q_values = np.max(next_q_values , axis = 1, keepdims= True)\n",
    "        #We can now compute the target value\n",
    "        y_val = reward + continues * self.discount_rate *max_next_q_values\n",
    "        _ , self.loss_val = self.sess.run([self.training_op, self.loss],\n",
    "                                          feed_dict= {self.X_state: np.array([state_val]),\n",
    "                                                      self.X_action: np.array([action_val]),\n",
    "                                                      self.y : y_val})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model for 1,000,000 Training Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-28c285c7b057>:6: conv2d (from tensorflow.python.keras.legacy_tf_layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Faizan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-28c285c7b057>:19: dense (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "INFO:tensorflow:Restoring parameters from ./my_dqn_assault.ckpt\n",
      "\t Training step 184639/1000000 (18.5)% \t Loss0.0012951"
     ]
    }
   ],
   "source": [
    "agent = QLearningAgent(env)\n",
    "\n",
    "\n",
    "n_steps = 1000000\n",
    "copy_steps = 5000\n",
    "save_steps = 1000\n",
    "\n",
    "with agent.sess:\n",
    "\n",
    "    state = preprocess_observation(env.reset())\n",
    "\n",
    "    while True:\n",
    "        step = agent.global_step.eval()\n",
    "        if step >= n_steps:\n",
    "            break\n",
    "\n",
    "\n",
    "        print(\"\\r\\t Training step {}/{} ({:.1f})% \\t Loss{:5f}\".format(step,n_steps,step*100/ n_steps,agent.loss_val), end=\"\")\n",
    "\n",
    "        if done:\n",
    "            obs = env.reset()\n",
    "            state = preprocess_observation(obs)\n",
    "\n",
    "        q_values = agent.online_q_values.eval(feed_dict={\n",
    "            agent.X_state : [state]})\n",
    "        action = agent.get_action(q_values,step)\n",
    "\n",
    "        #We play the action from the agent\n",
    "        next_obs, reward, done, info = env.step(action)\n",
    "        next_state = preprocess_observation(next_obs)\n",
    "        agent.train(state, action, reward, next_state, 1.0 - done)\n",
    "\n",
    "        env.render()\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        if step % copy_steps ==0:\n",
    "            agent.copy_online_to_target.run()\n",
    "\n",
    "        if step % save_steps ==0:\n",
    "            agent.saver.save(agent.sess, agent.checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyxQuhsvMG0p"
   },
   "source": [
    "# Reinforcement Learning with RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9sFk9WrTMb7z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJmMkfh8McdN"
   },
   "source": [
    "# Reinforcement Learning by Mixing Screen and RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7X1Em8i9znR",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CS4049_Assignment2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
